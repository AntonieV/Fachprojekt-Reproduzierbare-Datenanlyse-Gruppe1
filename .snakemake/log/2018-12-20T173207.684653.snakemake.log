Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	kallisto_quant
	1	sleuth
	2

[Thu Dec 20 17:32:08 2018]
rule kallisto_quant:
    input: kallisto/transcripts.idx, data/reads/b.chr21.1.fq, data/reads/b.chr21.2.fq
    output: kallisto/b
    jobid: 1
    wildcards: sample=b

kallisto quant -i kallisto/transcripts.idx -o  kallisto/b data/reads/b.chr21.1.fq data/reads/b.chr21.2.fq
[Thu Dec 20 17:32:08 2018]
Finished job 1.
1 of 2 steps (50%) done

[Thu Dec 20 17:32:08 2018]
rule sleuth:
    input: kallisto/a, kallisto/b
    output: /sleuth/significant_transcripts.csv
    jobid: 0

